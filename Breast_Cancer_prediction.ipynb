{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "165a3430-6cd7-471d-a932-475d193a8f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca889ce4d08747c2931fb2a48bc55999",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/33 [00:00<?, ?it/s]\u001b[A\n",
      " 39%|███▉      | 13/33 [00:00<00:00, 126.31it/s]\u001b[A\n",
      "100%|██████████| 33/33 [00:00<00:00, 114.02it/s]\u001b[A\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3b984ef2b914de1a192bbc66d876ae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b82710c8bd0940f988bf560a6512c9b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0c64b9e46a84661844a26a2aa88646a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, roc_auc_score, confusion_matrix, \n",
    "                             classification_report, roc_curve)\n",
    "from ydata_profiling import ProfileReport\n",
    "df = pd.read_csv('data.csv')\n",
    "profile = ProfileReport(\n",
    "    df,\n",
    "    title=\"Breast Cancer Data Profiling \"\n",
    ")\n",
    "profile.to_file(\"Breast_Cancer_report.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8deca9d4-ae5a-41da-b45f-6b4e6ff7f3ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
       "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
       "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
       "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
       "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
       "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
       "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
       "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
       "       'symmetry_worst', 'fractal_dimension_worst', 'Unnamed: 32'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb01f93a-a46c-4e95-aae6-c4ebda45fb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Unnamed: 32','id'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1327f75f-59ce-4067-a6f4-f0c978fa2a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diagnosis                  0\n",
       "radius_mean                0\n",
       "texture_mean               0\n",
       "perimeter_mean             0\n",
       "area_mean                  0\n",
       "smoothness_mean            0\n",
       "compactness_mean           0\n",
       "concavity_mean             0\n",
       "concave points_mean        0\n",
       "symmetry_mean              0\n",
       "fractal_dimension_mean     0\n",
       "radius_se                  0\n",
       "texture_se                 0\n",
       "perimeter_se               0\n",
       "area_se                    0\n",
       "smoothness_se              0\n",
       "compactness_se             0\n",
       "concavity_se               0\n",
       "concave points_se          0\n",
       "symmetry_se                0\n",
       "fractal_dimension_se       0\n",
       "radius_worst               0\n",
       "texture_worst              0\n",
       "perimeter_worst            0\n",
       "area_worst                 0\n",
       "smoothness_worst           0\n",
       "compactness_worst          0\n",
       "concavity_worst            0\n",
       "concave points_worst       0\n",
       "symmetry_worst             0\n",
       "fractal_dimension_worst    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea069b3d-cd1f-4297-a0cb-c203d1522c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ EDA visualizations saved as 'eda_analysis.png'\n",
      "✓ Correlation heatmap saved as 'correlation_heatmap.png'\n"
     ]
    }
   ],
   "source": [
    " #EDA\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "diag_counts = df['diagnosis'].value_counts()\n",
    "#df_encoded = df.copy()\n",
    "df['diagnosis'] = df['diagnosis'].map({'M': 1, 'B': 0})\n",
    "correlations = df.corr()['diagnosis'].abs().sort_values(ascending=False)\n",
    "\n",
    "# Plot 1: Diagnosis Distribution\n",
    "axes[0, 0].pie(diag_counts.values, labels=diag_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "axes[0, 0].set_title('Diagnosis Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Plot 2: Top 10 Correlations\n",
    "top_corr = correlations[1:11]\n",
    "axes[0, 1].barh(range(len(top_corr)), top_corr.values)\n",
    "axes[0, 1].set_yticks(range(len(top_corr)))\n",
    "axes[0, 1].set_yticklabels(top_corr.index)\n",
    "axes[0, 1].set_xlabel('Correlation with Diagnosis')\n",
    "axes[0, 1].set_title('Top 10 Features by Correlation', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].invert_yaxis()\n",
    "\n",
    "# Plot 3: Feature Groups Comparison\n",
    "feature_groups = {\n",
    "    'mean': [col for col in df.columns if '_mean' in col],\n",
    "    'se': [col for col in df.columns if '_se' in col],\n",
    "    'worst': [col for col in df.columns if '_worst' in col]\n",
    "}\n",
    "group_means = [df[feature_groups[g]].mean().mean() for g in ['mean', 'se', 'worst']]\n",
    "axes[1, 0].bar(['Mean', 'SE', 'Worst'], group_means, color=['skyblue', 'lightgreen', 'salmon'])\n",
    "axes[1, 0].set_ylabel('Average Value')\n",
    "axes[1, 0].set_title('Feature Groups Average', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Plot 4: Box plot for key features\n",
    "key_features = ['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean']\n",
    "df_melted = df[key_features + ['diagnosis']].melt(id_vars='diagnosis', var_name='Feature', value_name='Value')\n",
    "sns.boxplot(data=df_melted, x='Feature', y='Value', hue='diagnosis', ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Key Features Distribution by Diagnosis', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('eda_analysis.png', dpi=300, bbox_inches='tight')\n",
    "print(\"\\n✓ EDA visualizations saved as 'eda_analysis.png'\")\n",
    "\n",
    "# Correlation heatmap for top features\n",
    "plt.figure(figsize=(12, 10))\n",
    "top_features = correlations[1:16].index.tolist() + ['diagnosis']\n",
    "sns.heatmap(df[top_features].corr(), annot=True, fmt='.2f', cmap='coolwarm', center=0)\n",
    "plt.title('Correlation Heatmap - Top 15 Features', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('correlation_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "print(\"✓ Correlation heatmap saved as 'correlation_heatmap.png'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "961ec819-dc75-4ca3-b1c2-5070b5ecc7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#featuer engneering\n",
    "#df_engineered = df.copy()\n",
    "\n",
    "# 1. Ratio Features\n",
    "\n",
    "df['area_radius_ratio'] = df['area_mean'] / (df['radius_mean'] + 1e-5)\n",
    "df['perimeter_radius_ratio'] = df['perimeter_mean'] / (df['radius_mean'] + 1e-5)\n",
    "df['area_perimeter_ratio'] = df['area_mean'] / (df['perimeter_mean'] + 1e-5)\n",
    "\n",
    "# 2. Worst to Mean Ratios\n",
    "\n",
    "mean_features = [col for col in df.columns if '_mean' in col]\n",
    "for feature in mean_features:\n",
    "    feature_name = feature.replace('_mean', '')\n",
    "    worst_col = f'{feature_name}_worst'\n",
    "    if worst_col in df.columns:\n",
    "        df[f'{feature_name}_worst_mean_ratio'] = df[worst_col] / (df[feature] + 1e-5)\n",
    "\n",
    "# 3. SE to Mean Ratios (Coefficient of Variation)\n",
    "\n",
    "for feature in mean_features:\n",
    "    feature_name = feature.replace('_mean', '')\n",
    "    se_col = f'{feature_name}_se'\n",
    "    if se_col in df.columns:\n",
    "        df[f'{feature_name}_cv'] = df[se_col] / (df[feature] + 1e-5)\n",
    "\n",
    "# 4. Aggregate Features by Groups\n",
    "\n",
    "df['mean_group_avg'] = df[[col for col in df.columns if '_mean' in col]].mean(axis=1)\n",
    "df['se_group_avg'] = df[[col for col in df.columns if '_se' in col]].mean(axis=1)\n",
    "df['worst_group_avg'] = df[[col for col in df.columns if '_worst' in col]].mean(axis=1)\n",
    "\n",
    "df['mean_group_std'] = df[[col for col in df.columns if '_mean' in col]].std(axis=1)\n",
    "df['worst_group_std'] = df[[col for col in df.columns if '_worst' in col]].std(axis=1)\n",
    "\n",
    "# 5. Interaction Features\n",
    "\n",
    "df['concavity_compactness'] = df['concavity_mean'] * df['compactness_mean']\n",
    "df['radius_texture_interaction'] = df['radius_mean'] * df['texture_mean']\n",
    "df['area_smoothness_interaction'] = df['area_mean'] * df['smoothness_mean']\n",
    "df['perimeter_concavity_interaction'] = df['perimeter_mean'] * df['concavity_mean']\n",
    "\n",
    "# 6. Polynomial Features (for highly correlated features)\n",
    "\n",
    "df['radius_mean_squared'] = df['radius_mean'] ** 2\n",
    "df['area_mean_squared'] = df['area_mean'] ** 2\n",
    "df['concavity_mean_squared'] = df['concavity_mean'] ** 2\n",
    "df['concave_points_mean_squared'] = df['concave points_mean'] ** 2\n",
    "\n",
    "# 7. Domain-Specific Features\n",
    "\n",
    "# Tumor irregularity score\n",
    "df['tumor_irregularity'] = (df['concavity_mean'] + df['concave points_mean'] + \n",
    "                                        df['compactness_mean']) / 3\n",
    "\n",
    "# Size score\n",
    "df['size_score'] = (df['radius_mean'] + df['perimeter_mean'] + df['area_mean']) / 3\n",
    "\n",
    "# Texture complexity\n",
    "df['texture_complexity'] = df['texture_mean'] * df['fractal_dimension_mean']\n",
    "\n",
    "# Overall worst features score\n",
    "worst_features = [col for col in df.columns if '_worst' in col]\n",
    "df['worst_features_score'] = df[worst_features].mean(axis=1)\n",
    "\n",
    "# 8. Log Transformations (for skewed features)\n",
    "\n",
    "skewed_features = ['area_mean', 'area_se', 'area_worst', 'perimeter_mean', 'radius_mean']\n",
    "for feature in skewed_features:\n",
    "    if feature in df.columns:\n",
    "        df[f'{feature}_log'] = np.log1p(df[feature])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79b1fd1a-6131-4396-8312-67c5a53b4d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
       "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
       "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
       "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
       "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
       "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
       "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
       "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
       "       'symmetry_worst', 'fractal_dimension_worst', 'area_radius_ratio',\n",
       "       'perimeter_radius_ratio', 'area_perimeter_ratio',\n",
       "       'radius_worst_mean_ratio', 'texture_worst_mean_ratio',\n",
       "       'perimeter_worst_mean_ratio', 'area_worst_mean_ratio',\n",
       "       'smoothness_worst_mean_ratio', 'compactness_worst_mean_ratio',\n",
       "       'concavity_worst_mean_ratio', 'concave points_worst_mean_ratio',\n",
       "       'symmetry_worst_mean_ratio', 'fractal_dimension_worst_mean_ratio',\n",
       "       'radius_cv', 'texture_cv', 'perimeter_cv', 'area_cv', 'smoothness_cv',\n",
       "       'compactness_cv', 'concavity_cv', 'concave points_cv', 'symmetry_cv',\n",
       "       'fractal_dimension_cv', 'mean_group_avg', 'se_group_avg',\n",
       "       'worst_group_avg', 'mean_group_std', 'worst_group_std',\n",
       "       'concavity_compactness', 'radius_texture_interaction',\n",
       "       'area_smoothness_interaction', 'perimeter_concavity_interaction',\n",
       "       'radius_mean_squared', 'area_mean_squared', 'concavity_mean_squared',\n",
       "       'concave_points_mean_squared', 'tumor_irregularity', 'size_score',\n",
       "       'texture_complexity', 'worst_features_score', 'area_mean_log',\n",
       "       'area_se_log', 'area_worst_log', 'perimeter_mean_log',\n",
       "       'radius_mean_log'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "672e39a6-5a01-49dc-9bf6-6e3049c7e6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model_1_Default...\n",
      "   ✓ Test Accuracy: 0.9737\n",
      "Training Model_2_L1_Regularization...\n",
      "   ✓ Test Accuracy: 0.9737\n",
      "Training Model_3_Strong_L2_Regularization...\n",
      "   ✓ Test Accuracy: 0.9561\n",
      "Training Model_4_Weak_L2_Regularization...\n",
      "   ✓ Test Accuracy: 0.9474\n",
      "Training Model_5_ElasticNet...\n",
      "   ✓ Test Accuracy: 0.9737\n",
      "Training Model_6_No_Regularization...\n",
      "   ✓ Test Accuracy: 0.9211\n",
      "Training Model_7_Newton_Solver...\n",
      "   ✓ Test Accuracy: 0.9737\n",
      "Training Model_8_SAG_Solver...\n",
      "   ✓ Test Accuracy: 0.9737\n",
      "Training Model_9_Balanced_Class_Weight...\n",
      "   ✓ Test Accuracy: 0.9825\n",
      "Training Model_10_L1_Strong_Reg...\n",
      "   ✓ Test Accuracy: 0.9649\n"
     ]
    }
   ],
   "source": [
    "#Modeling\n",
    "X = df.drop('diagnosis', axis=1)\n",
    "y = df['diagnosis']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "models_config = {\n",
    "    'Model_1_Default': {\n",
    "        'penalty': 'l2',\n",
    "        'C': 1.0,\n",
    "        'solver': 'lbfgs',\n",
    "        'max_iter': 1000\n",
    "    },\n",
    "    'Model_2_L1_Regularization': {\n",
    "        'penalty': 'l1',\n",
    "        'C': 1.0,\n",
    "        'solver': 'liblinear',\n",
    "        'max_iter': 1000\n",
    "    },\n",
    "    'Model_3_Strong_L2_Regularization': {\n",
    "        'penalty': 'l2',\n",
    "        'C': 0.01,\n",
    "        'solver': 'lbfgs',\n",
    "        'max_iter': 1000\n",
    "    },\n",
    "    'Model_4_Weak_L2_Regularization': {\n",
    "        'penalty': 'l2',\n",
    "        'C': 10.0,\n",
    "        'solver': 'lbfgs',\n",
    "        'max_iter': 1000\n",
    "    },\n",
    "    'Model_5_ElasticNet': {\n",
    "        'penalty': 'elasticnet',\n",
    "        'C': 1.0,\n",
    "        'solver': 'saga',\n",
    "        'l1_ratio': 0.5,\n",
    "        'max_iter': 2000\n",
    "    },\n",
    "    'Model_6_No_Regularization': {\n",
    "        'penalty': None,\n",
    "        'C': 1.0,\n",
    "        'solver': 'lbfgs',\n",
    "        'max_iter': 1000\n",
    "    },\n",
    "    'Model_7_Newton_Solver': {\n",
    "        'penalty': 'l2',\n",
    "        'C': 1.0,\n",
    "        'solver': 'newton-cg',\n",
    "        'max_iter': 1000\n",
    "    },\n",
    "    'Model_8_SAG_Solver': {\n",
    "        'penalty': 'l2',\n",
    "        'C': 1.0,\n",
    "        'solver': 'sag',\n",
    "        'max_iter': 1000\n",
    "    },\n",
    "    'Model_9_Balanced_Class_Weight': {\n",
    "        'penalty': 'l2',\n",
    "        'C': 1.0,\n",
    "        'solver': 'lbfgs',\n",
    "        'class_weight': 'balanced',\n",
    "        'max_iter': 1000\n",
    "    },\n",
    "    'Model_10_L1_Strong_Reg': {\n",
    "        'penalty': 'l1',\n",
    "        'C': 0.1,\n",
    "        'solver': 'liblinear',\n",
    "        'max_iter': 1000\n",
    "    }\n",
    "}\n",
    "results = []\n",
    "trained_models = {}\n",
    "for model_name, params in models_config.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    model = LogisticRegression(random_state=42, **params)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred_train = model.predict(X_train_scaled)\n",
    "    y_pred_test = model.predict(X_test_scaled)\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    cv_scores = cross_val_score(model, X_train_scaled, y_train, \n",
    "                                cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "                                scoring='accuracy')\n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'Train_Accuracy': accuracy_score(y_train, y_pred_train),\n",
    "        'Test_Accuracy': accuracy_score(y_test, y_pred_test),\n",
    "        'Precision': precision_score(y_test, y_pred_test),\n",
    "        'Recall': recall_score(y_test, y_pred_test),\n",
    "        'F1_Score': f1_score(y_test, y_pred_test),\n",
    "        'ROC_AUC': roc_auc_score(y_test, y_pred_proba),\n",
    "        'CV_Mean': cv_scores.mean(),\n",
    "        'CV_Std': cv_scores.std(),\n",
    "        'Params': str(params)\n",
    "    })\n",
    "    \n",
    "    trained_models[model_name] = {\n",
    "        'model': model,\n",
    "        'y_pred': y_pred_test,\n",
    "        'y_pred_proba': y_pred_proba\n",
    "    }\n",
    "    \n",
    "    print(f\"   ✓ Test Accuracy: {accuracy_score(y_test, y_pred_test):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a82fa0a2-ddb2-410c-a983-d975088ada48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODELS COMPARISON - SORTED BY TEST ACCURACY\n",
      "================================================================================\n",
      "                           Model  Test_Accuracy  Precision   Recall  F1_Score  ROC_AUC\n",
      "   Model_9_Balanced_Class_Weight       0.982456   0.976190 0.976190  0.976190 0.995701\n",
      "                 Model_1_Default       0.973684   0.975610 0.952381  0.963855 0.997024\n",
      "       Model_2_L1_Regularization       0.973684   0.975610 0.952381  0.963855 0.997024\n",
      "              Model_5_ElasticNet       0.973684   0.975610 0.952381  0.963855 0.996693\n",
      "           Model_7_Newton_Solver       0.973684   0.975610 0.952381  0.963855 0.997024\n",
      "              Model_8_SAG_Solver       0.973684   0.975610 0.952381  0.963855 0.997024\n",
      "          Model_10_L1_Strong_Reg       0.964912   0.975000 0.928571  0.951220 0.997685\n",
      "Model_3_Strong_L2_Regularization       0.956140   1.000000 0.880952  0.936709 0.999339\n",
      "  Model_4_Weak_L2_Regularization       0.947368   0.928571 0.928571  0.928571 0.990741\n",
      "       Model_6_No_Regularization       0.921053   0.923077 0.857143  0.888889 0.967923\n",
      "\n",
      "================================================================================\n",
      "BEST MODEL: Model_9_Balanced_Class_Weight\n",
      "================================================================================\n",
      "\n",
      "Detailed Performance Metrics:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Benign (0)       0.99      0.99      0.99        72\n",
      "Malignant (1)       0.98      0.98      0.98        42\n",
      "\n",
      "     accuracy                           0.98       114\n",
      "    macro avg       0.98      0.98      0.98       114\n",
      " weighted avg       0.98      0.98      0.98       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('Test_Accuracy', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODELS COMPARISON - SORTED BY TEST ACCURACY\")\n",
    "print(\"=\"*80)\n",
    "print(results_df[['Model', 'Test_Accuracy', 'Precision', 'Recall', 'F1_Score', 'ROC_AUC']].to_string(index=False))\n",
    "\n",
    "# 5. Find Best Model\n",
    "best_model_name = results_df.iloc[0]['Model']\n",
    "best_model_info = trained_models[best_model_name]\n",
    "best_model = best_model_info['model']\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"BEST MODEL: {best_model_name}\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nDetailed Performance Metrics:\")\n",
    "print(classification_report(y_test, best_model_info['y_pred'], \n",
    "                          target_names=['Benign (0)', 'Malignant (1)']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2773700d-a218-49b3-aade-2d20028e73bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "   True Negatives:  71\n",
      "   False Positives: 1\n",
      "   False Negatives: 1\n",
      "   True Positives:  41\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, best_model_info['y_pred'])\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(f\"   True Negatives:  {cm[0, 0]}\")\n",
    "print(f\"   False Positives: {cm[0, 1]}\")\n",
    "print(f\"   False Negatives: {cm[1, 0]}\")\n",
    "print(f\"   True Positives:  {cm[1, 1]}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c5e41f2-5547-4aa6-8be4-42ac4147599a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "GRID SEARCH - FINE-TUNING BEST PERFORMING CONFIGURATION\n",
      "================================================================================\n",
      "\n",
      "Searching through 18 combinations...\n",
      "\n",
      "✓ Best Parameters: {'C': 1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "✓ Best CV Score: 0.9714\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV for Fine-tuning Best Model Type\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GRID SEARCH - FINE-TUNING BEST PERFORMING CONFIGURATION\")\n",
    "print(\"=\"*80)\n",
    "best_penalty = models_config[best_model_name].get('penalty', 'l2')\n",
    "\n",
    "if best_penalty == 'elasticnet':\n",
    "    param_grid = {\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "        'solver': ['saga'],\n",
    "        'penalty': ['elasticnet'],\n",
    "        'max_iter': [2000]\n",
    "    }\n",
    "elif best_penalty == 'l1':\n",
    "    param_grid = {\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'solver': ['liblinear', 'saga'],\n",
    "        'penalty': ['l1'],\n",
    "        'max_iter': [1000, 2000]\n",
    "    }\n",
    "else:\n",
    "    param_grid = {\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'solver': ['lbfgs', 'newton-cg', 'sag'],\n",
    "        'penalty': ['l2'],\n",
    "        'max_iter': [1000, 2000]\n",
    "    }\n",
    "\n",
    "print(f\"\\nSearching through {len(param_grid['C']) * len(param_grid['solver'])} combinations...\")\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    LogisticRegression(random_state=42),\n",
    "    param_grid,\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"\\n✓ Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"✓ Best CV Score: {grid_search.best_score_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "805a7494-b7e2-4e1b-9275-f1e5324c9da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Grid Search Best Model Test Performance:\n",
      "   Accuracy:  0.9737\n",
      "   Precision: 0.9756\n",
      "   Recall:    0.9524\n",
      "   F1-Score:  0.9639\n",
      "   ROC-AUC:   0.9970\n"
     ]
    }
   ],
   "source": [
    "# Evaluate grid search best model\n",
    "best_grid_model = grid_search.best_estimator_\n",
    "y_pred_grid = best_grid_model.predict(X_test_scaled)\n",
    "y_pred_proba_grid = best_grid_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"\\nGrid Search Best Model Test Performance:\")\n",
    "print(f\"   Accuracy:  {accuracy_score(y_test, y_pred_grid):.4f}\")\n",
    "print(f\"   Precision: {precision_score(y_test, y_pred_grid):.4f}\")\n",
    "print(f\"   Recall:    {recall_score(y_test, y_pred_grid):.4f}\")\n",
    "print(f\"   F1-Score:  {f1_score(y_test, y_pred_grid):.4f}\")\n",
    "print(f\"   ROC-AUC:   {roc_auc_score(y_test, y_pred_proba_grid):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "646536b6-1f44-466a-91a7-b27b19825a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Visualizations saved as 'logistic_regression_comparison.png'\n"
     ]
    }
   ],
   "source": [
    "# Visualizations\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Plot 1: Model Comparison - Test Accuracy\n",
    "axes[0, 0].barh(results_df['Model'], results_df['Test_Accuracy'], color='skyblue')\n",
    "axes[0, 0].set_xlabel('Test Accuracy')\n",
    "axes[0, 0].set_title('Model Comparison - Test Accuracy', fontweight='bold')\n",
    "axes[0, 0].axvline(x=results_df['Test_Accuracy'].max(), color='red', linestyle='--', linewidth=1)\n",
    "\n",
    "# Plot 2: Precision vs Recall\n",
    "axes[0, 1].scatter(results_df['Recall'], results_df['Precision'], s=100, alpha=0.6)\n",
    "for i, model in enumerate(results_df['Model']):\n",
    "    axes[0, 1].annotate(f\"M{i+1}\", (results_df['Recall'].iloc[i], results_df['Precision'].iloc[i]))\n",
    "axes[0, 1].set_xlabel('Recall')\n",
    "axes[0, 1].set_ylabel('Precision')\n",
    "axes[0, 1].set_title('Precision vs Recall Trade-off', fontweight='bold')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: F1-Score Comparison\n",
    "axes[0, 2].bar(range(len(results_df)), results_df['F1_Score'], color='lightgreen')\n",
    "axes[0, 2].set_xticks(range(len(results_df)))\n",
    "axes[0, 2].set_xticklabels([f\"M{i+1}\" for i in range(len(results_df))], rotation=45)\n",
    "axes[0, 2].set_ylabel('F1-Score')\n",
    "axes[0, 2].set_title('F1-Score Comparison', fontweight='bold')\n",
    "\n",
    "# Plot 4: ROC Curves for Top 3 Models\n",
    "for i, model_name in enumerate(results_df['Model'].head(3)):\n",
    "    fpr, tpr, _ = roc_curve(y_test, trained_models[model_name]['y_pred_proba'])\n",
    "    auc = results_df[results_df['Model'] == model_name]['ROC_AUC'].values[0]\n",
    "    axes[1, 0].plot(fpr, tpr, label=f'{model_name} (AUC={auc:.3f})')\n",
    "axes[1, 0].plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "axes[1, 0].set_xlabel('False Positive Rate')\n",
    "axes[1, 0].set_ylabel('True Positive Rate')\n",
    "axes[1, 0].set_title('ROC Curves - Top 3 Models', fontweight='bold')\n",
    "axes[1, 0].legend(fontsize=8)\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 5: Confusion Matrix - Best Model\n",
    "cm = confusion_matrix(y_test, best_model_info['y_pred'])\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[1, 1])\n",
    "axes[1, 1].set_xlabel('Predicted')\n",
    "axes[1, 1].set_ylabel('Actual')\n",
    "axes[1, 1].set_title(f'Confusion Matrix - {best_model_name}', fontweight='bold')\n",
    "\n",
    "# Plot 6: Train vs Test Accuracy\n",
    "x_pos = np.arange(len(results_df))\n",
    "width = 0.35\n",
    "axes[1, 2].bar(x_pos - width/2, results_df['Train_Accuracy'], width, label='Train', alpha=0.8)\n",
    "axes[1, 2].bar(x_pos + width/2, results_df['Test_Accuracy'], width, label='Test', alpha=0.8)\n",
    "axes[1, 2].set_xticks(x_pos)\n",
    "axes[1, 2].set_xticklabels([f\"M{i+1}\" for i in range(len(results_df))], rotation=45)\n",
    "axes[1, 2].set_ylabel('Accuracy')\n",
    "axes[1, 2].set_title('Train vs Test Accuracy (Overfitting Check)', fontweight='bold')\n",
    "axes[1, 2].legend()\n",
    "axes[1, 2].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('logistic_regression_comparison.png', dpi=300, bbox_inches='tight')\n",
    "print(\"\\n✓ Visualizations saved as 'logistic_regression_comparison.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "602b2eda-13e2-48d8-b3ea-85d846abbc5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Feature  Coefficient\n",
      "                        area_cv     0.906403\n",
      "              concave points_se     0.813186\n",
      "                  texture_worst     0.788503\n",
      "            concave points_mean     0.730461\n",
      "       texture_worst_mean_ratio     0.707673\n",
      "                   texture_mean     0.682469\n",
      "                      radius_cv     0.615000\n",
      "                concavity_worst     0.608330\n",
      "           concave points_worst     0.599559\n",
      "     concavity_worst_mean_ratio     0.595926\n",
      "     radius_texture_interaction     0.590201\n",
      "          area_worst_mean_ratio     0.586283\n",
      "    concave_points_mean_squared     0.544223\n",
      "           fractal_dimension_se     0.538753\n",
      "                 compactness_se     0.533036\n",
      "perimeter_concavity_interaction     0.517150\n",
      "                 symmetry_worst     0.515961\n",
      "                 concavity_mean     0.504223\n",
      "               compactness_mean     0.498842\n",
      "                      radius_se     0.417437\n",
      "\n",
      "✓ Feature importance plot saved as 'feature_importance.png'\n"
     ]
    }
   ],
   "source": [
    "# Feature Importance (Top 20)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': np.abs(best_grid_model.coef_[0])\n",
    "}).sort_values('Coefficient', ascending=False)\n",
    "\n",
    "print(feature_importance.head(20).to_string(index=False))\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 8))\n",
    "top_features = feature_importance.head(20)\n",
    "plt.barh(range(len(top_features)), top_features['Coefficient'])\n",
    "plt.yticks(range(len(top_features)), top_features['Feature'])\n",
    "plt.xlabel('Absolute Coefficient Value')\n",
    "plt.title('Top 20 Most Important Features', fontweight='bold', fontsize=14)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "print(\"\\n✓ Feature importance plot saved as 'feature_importance.png'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21fa9e82-a6f0-4259-a303-be4e998008de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Results saved as 'model_comparison_results.csv'\n"
     ]
    }
   ],
   "source": [
    "#  Save Results\n",
    "results_df.to_csv('model_comparison_results.csv', index=False)\n",
    "print(\"\\n✓ Results saved as 'model_comparison_results.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17445e53-710e-42ea-b103-a3ea66d0afe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Best model saved as 'best_logistic_model.pkl'\n",
      "✓ Scaler saved as 'scaler.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('best_logistic_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_grid_model, f)\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(\"✓ Best model saved as 'best_logistic_model.pkl'\")\n",
    "print(\"✓ Scaler saved as 'scaler.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cb7a3d-252d-48ee-b461-8d96cd8cc470",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
